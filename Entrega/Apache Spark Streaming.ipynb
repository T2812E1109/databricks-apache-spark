{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso práctico con  Spark Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este noteboo se utilizarán los datos de Kaggle de fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T05:30:51.892756Z",
     "end_time": "2023-04-28T05:30:51.906773Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T05:30:51.906773Z",
     "end_time": "2023-04-28T05:30:59.748661Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext nb_black\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T05:30:59.750173Z",
     "end_time": "2023-04-28T05:31:05.692348Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data/fraud_detection.csv\", \n",
    "                    header=True, \n",
    "                    inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T05:31:05.694567Z",
     "end_time": "2023-04-28T05:31:05.752204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['step',\n 'type',\n 'amount',\n 'nameOrig',\n 'oldbalanceOrg',\n 'newbalanceOrig',\n 'nameDest',\n 'oldbalanceDest',\n 'newbalanceDest',\n 'isFraud',\n 'isFlaggedFraud']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T05:33:31.548193Z",
     "end_time": "2023-04-28T05:33:31.560207Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"isFraud\", \"isFlaggedFraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T05:33:59.224978Z",
     "end_time": "2023-04-28T05:33:59.292478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
      "|step|    type|   amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|\n",
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
      "|   1| PAYMENT|  9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|\n",
      "|   1| PAYMENT|  1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|\n",
      "|   1|TRANSFER|    181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|\n",
      "|   1|CASH_OUT|    181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|\n",
      "|   1| PAYMENT| 11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|\n",
      "|   1| PAYMENT|  7817.71|  C90045638|      53860.0|      46042.29| M573487274|           0.0|           0.0|\n",
      "|   1| PAYMENT|  7107.77| C154988899|     183195.0|     176087.23| M408069119|           0.0|           0.0|\n",
      "|   1| PAYMENT|  7861.64|C1912850431|    176087.23|     168225.59| M633326333|           0.0|           0.0|\n",
      "|   1| PAYMENT|  4024.36|C1265012928|       2671.0|           0.0|M1176932104|           0.0|           0.0|\n",
      "|   1|   DEBIT|  5337.77| C712410124|      41720.0|      36382.23| C195600860|       41898.0|      40348.79|\n",
      "|   1|   DEBIT|  9644.94|C1900366749|       4465.0|           0.0| C997608398|       10845.0|     157982.12|\n",
      "|   1| PAYMENT|  3099.97| C249177573|      20771.0|      17671.03|M2096539129|           0.0|           0.0|\n",
      "|   1| PAYMENT|  2560.74|C1648232591|       5070.0|       2509.26| M972865270|           0.0|           0.0|\n",
      "|   1| PAYMENT| 11633.76|C1716932897|      10127.0|           0.0| M801569151|           0.0|           0.0|\n",
      "|   1| PAYMENT|  4098.78|C1026483832|     503264.0|     499165.22|M1635378213|           0.0|           0.0|\n",
      "|   1|CASH_OUT|229133.94| C905080434|      15325.0|           0.0| C476402209|        5083.0|      51513.44|\n",
      "|   1| PAYMENT|  1563.82| C761750706|        450.0|           0.0|M1731217984|           0.0|           0.0|\n",
      "|   1| PAYMENT|  1157.86|C1237762639|      21156.0|      19998.14|M1877062907|           0.0|           0.0|\n",
      "|   1| PAYMENT|   671.64|C2033524545|      15123.0|      14451.36| M473053293|           0.0|           0.0|\n",
      "|   1|TRANSFER| 215310.3|C1670993182|        705.0|           0.0|C1100439041|       22425.0|           0.0|\n",
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step maps a unit of time in the real world. In this case 1 step is 1 hour of time. So we can assume for this example that we have another job that runs every hour and gets all the transactions in that time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T05:33:37.718810Z",
     "end_time": "2023-04-28T05:33:38.879553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|step|count|\n",
      "+----+-----+\n",
      "|  12|36153|\n",
      "|   1| 2708|\n",
      "|  13|37515|\n",
      "+----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"step\").count().show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore save the output of that job by filtering on each step and saving it to a separate file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'steps = df.select(\"step\").distinct().collect()\\nfor step in steps[:]:\\n    _df = df.where(f\"step = {step[0]}\")\\n    #by adding coalesce(1) we save the dataframe to one file\\n    _df.coalesce(1).write.mode(\"append\").option(\"header\", \"true\").csv(\"data/fraud\")'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"steps = df.select(\"step\").distinct().collect()\n",
    "for step in steps[:]:\n",
    "    _df = df.where(f\"step = {step[0]}\")\n",
    "    #by adding coalesce(1) we save the dataframe to one file\n",
    "    _df.coalesce(1).write.mode(\"append\").option(\"header\", \"true\").csv(\"data/fraud\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data/fraud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = spark.read.csv(\n",
    "    \"data/fraud/part-00000-897a9dd3-832b-4e43-bcdc-c0009cfec4f0-c000.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|step|count|\n",
      "+----+-----+\n",
      "|  34|30904|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "part.groupBy(\"step\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a streaming version of this input, we'll read each file one by one as if it was a stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema = part.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(step,IntegerType,true),StructField(type,StringType,true),StructField(amount,DoubleType,true),StructField(nameOrig,StringType,true),StructField(oldbalanceOrg,DoubleType,true),StructField(newbalanceOrig,DoubleType,true),StructField(nameDest,StringType,true),StructField(oldbalanceDest,DoubleType,true),StructField(newbalanceDest,DoubleType,true)))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*maxFilesPerTrigger* allows you to control how quickly Spark will read all of the files in the folder. \n",
    "In this example we're limiting the flow of the stream to one file per trigger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = (\n",
    "    spark.readStream.schema(dataSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .csv(\"data/fraud/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a transformation.\n",
    "\n",
    "The nameDest column is the recipient ID of the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_count = streaming.groupBy(\"nameDest\").count().orderBy(F.desc(\"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our transformation, we need to specify an output sink for the results. For this example, we're going to write to a memory sink which keeps the results in memory.\n",
    "\n",
    "We also need to define how Spark will output that data. In this example, we'll use the complete output mode (rewriting all of the keys along with their counts after every trigger).\n",
    "\n",
    "In this example we won't include activityQuery.awaitTermination() because it is required only to prevent the driver process from terminating when the stream is active.\n",
    "\n",
    "So in order to be able to run this locally in a notebook we won't include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C319921943|    2|\n",
      "| C803352127|    2|\n",
      "|C1887077333|    2|\n",
      "| C763794011|    2|\n",
      "| C488343370|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C587204551|    2|\n",
      "|C1015743493|    2|\n",
      "| C359227905|    2|\n",
      "|C1850343194|    2|\n",
      "| C379236140|    2|\n",
      "| C319921943|    2|\n",
      "|C1377194794|    2|\n",
      "|C1455885936|    2|\n",
      "| C803352127|    2|\n",
      "| C325257804|    2|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C587204551|    2|\n",
      "|C1015743493|    2|\n",
      "| C359227905|    2|\n",
      "|C1850343194|    2|\n",
      "| C379236140|    2|\n",
      "| C319921943|    2|\n",
      "|C1377194794|    2|\n",
      "|C1455885936|    2|\n",
      "| C803352127|    2|\n",
      "| C325257804|    2|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------+-----+\n",
      "|   nameDest|count|\n",
      "+-----------+-----+\n",
      "| C587204551|    2|\n",
      "|C1015743493|    2|\n",
      "| C359227905|    2|\n",
      "|C1850343194|    2|\n",
      "| C379236140|    2|\n",
      "| C319921943|    2|\n",
      "|C1377194794|    2|\n",
      "|C1455885936|    2|\n",
      "| C803352127|    2|\n",
      "| C325257804|    2|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activityQuery = (\n",
    "    dest_count.writeStream.queryName(\"dest_counts\")\n",
    "    .format(\"memory\")\n",
    "    .outputMode(\"complete\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "# include this in production\n",
    "# activityQuery.awaitTermination()\n",
    "\n",
    "import time\n",
    "\n",
    "for x in range(50):\n",
    "    _df = spark.sql(\n",
    "        \"SELECT * FROM dest_counts WHERE nameDest != 'nameDest' AND count >= 2\"\n",
    "    )\n",
    "    if _df.count() > 0:\n",
    "        _df.show(10)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if stream is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active[0].isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activityQuery.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we  want to turn off the stream we'll run activityQuery.stop() to reset the query for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "activityQuery.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
